{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aist2000/ML-public/blob/master/DEV_Bus_Differential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCv3DQ67PXvE"
      },
      "source": [
        "# Electric BUS\n",
        "[Diagram](https://www.webgreenstation.com/bus-differential-element-ge-ur-multilin-settings-gu8012/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXEJJ7QPZId"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import array as arr\n",
        "from sklearn import datasets, linear_model, metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyerQEzJGOgz"
      },
      "source": [
        "url=\"https://raw.githubusercontent.com/aist2000/ML-public/master/dataset.csv\"\n",
        "#url=\"dataset.csv\"\n",
        "df = pd.read_csv(url, skiprows=0)\n",
        "display(df.head())\n",
        "display(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histogram to see distribution of data points\n",
        "import seaborn as sns\n",
        "sns.pairplot(data=df, diag_kind='kde', vars=['X1','X2','X3','X4'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vlHl56iqgwH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC-e8G-cC8Pw"
      },
      "source": [
        "X = df[df.columns[0:4]]\n",
        "y = df[['Y']]\n",
        "#X=X.rename(columns={0:'X1',1:'X2', 2:'X3', 3:'X4', 4:'label'})\n",
        "#y = df[['Status']].rename(columns={'Status':'label'})\n",
        "\n",
        "Xs = X\n",
        "display(X.head())\n",
        "display(y.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train and test \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
      ],
      "metadata": {
        "id": "IK-xFKWo5k0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-14T06:17:32.581431Z",
          "start_time": "2021-06-14T06:17:32.529124Z"
        },
        "id": "1fJFffUPMmcc"
      },
      "outputs": [],
      "source": [
        "# scale features\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "numeric=['X1','X2','X3','X4']\n",
        "sc=StandardScaler()\n",
        "X_train[numeric]=sc.fit_transform(X_train[numeric])\n",
        "X_test[numeric]=sc.transform(X_test[numeric])\n",
        "display( \"Train\", X_train.describe() )\n",
        "display( \"Test\", X_test.describe() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Lvz6OvVCAq"
      },
      "source": [
        "**Scilearn Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqSsTc5UXLwZ"
      },
      "source": [
        "#  Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "model = LogisticRegression(solver=\"liblinear\", C= 1 )\n",
        "#model = LogisticRegression(max_iter =400, solver='lbfgs')\n",
        "\n",
        "# fit the model with data\n",
        "y_t=y_train.to_numpy().reshape(-1)\n",
        "\n",
        "model.fit(X_train, y_t)\n",
        "\n",
        "display(model.coef_, model.intercept_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeM5qQfcn4wv"
      },
      "source": [
        "# predict Sample with Logistic Regression\n",
        "#x_t =[[8,0,1.61,-205],[8.0, 0, 1.61, -35],[2.0, 0, 2.00, -165] ,[4.5, 0, 0.89, -245]]\n",
        "\n",
        "# train accuracy\n",
        "model_accuracy=model.score(X_train,  y_train)\n",
        "y_pred= model.predict( X_train)\n",
        "calc_accuracy =  sum(y_pred == y_train.Y) /  y_train.Y.count()\n",
        "print(\"Train  Count={}; Model Accuracy= {} ; Calculated Accuracy={}\".format( y_train.Y.count(), model_accuracy, calc_accuracy) )\n",
        "\n",
        "# test accuracy\n",
        "x_t = X_test.head()\n",
        "y_t = y_test.head()\n",
        "#print(X_test.head(), y_test.head())\n",
        "pred1= model.predict( x_t)\n",
        "#proba1= model.predict_proba( np.array(x_t, ndmin=2) )\n",
        "proba1= model.predict_proba(x_t)\n",
        "print(\"For parameters = {} \\n{}, \\n we predict {} proba={}\".format(x_t, y_t, pred1, proba1[:,1]))\n",
        "\n",
        "model_accuracy=model.score(X_test,  y_test.Y)\n",
        "y_pred= model.predict( X_test)\n",
        "calc_accuracy =  sum(y_pred == y_test.Y) /  y_test.Y.count()\n",
        "print(\"Test  Count={}; Model Accuracy= {} ; Calculated Accuracy={}\".format( y_test.Y.count(), model_accuracy, calc_accuracy) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Vector Machine SVM\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "\n",
        "y_t=y_train.to_numpy().reshape(-1)\n",
        "model.fit(X_train, y_t)\n",
        "\n",
        "\n",
        "#print(clf.predict([[-0.8, -1]]))"
      ],
      "metadata": {
        "id": "TrfyKb8h9F5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict Sample with SVM\n",
        "x_t =[[-0.620128,\t0.0\t,0.199953,\t0.130023],[1.870952,\t0.0,\t0.000548,\t-0.730424],[2.0, 0, 2.00, -165] ,[4.5, 0, 0.89, -245]]\n",
        "pred1= model.predict( x_t)\n",
        "#proba1= model.predict_proba(x_t)\n",
        "print(\"For parameters = {}, \\n we predict {} \".format(x_t, pred1))\n",
        "\n",
        "# train accuracy\n",
        "model_accuracy=model.score(X_train,  y_train.Y)\n",
        "y_pred= model.predict( X_train)\n",
        "calc_accuracy =  sum(y_pred == y_train.Y) /  y_train.Y.count()\n",
        "print(\"Train  Count={}; Model Accuracy= {} ; Calculated Accuracy={}\".format( y_train.Y.count(), model_accuracy, calc_accuracy) )\n",
        "\n",
        "# test accuracy\n",
        "x_t = X_test.head()\n",
        "y_t = y_test.head()\n",
        "#print(X_test.head(), y_test.head())\n",
        "pred1= model.predict( x_t)\n",
        "#proba1= model.predict_proba(x_t)\n",
        "print(\"For parameters = {}{}, \\n we predict {} \".format(x_t, y_t, pred1))\n",
        "\n",
        "model_accuracy=model.score(X_test,  y_test.Y)\n",
        "y_pred= model.predict( X_test)\n",
        "calc_accuracy =  sum(y_pred == y_test.Y) /  y_test.Y.count()\n",
        "print(\"Test  Count={}; Model Accuracy= {} ; Calculated Accuracy={}\".format( y_test.Y.count(), model_accuracy, calc_accuracy) )\n",
        "print(X_test[y_pred != y_test.Y].count())\n",
        "print(y_test[y_pred != y_test.Y].head(10))\n",
        "print(y_pred[y_pred != y_test.Y])"
      ],
      "metadata": {
        "id": "_MwNly0F-PmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRSWrlxpEDYu"
      },
      "source": [
        "# Polynomial Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-s_CmVXDcy0"
      },
      "source": [
        "# Polynomial Boundary\n",
        "# import the class\n",
        "import matplotlib.pyplot as pltp\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# apply Regularization C=1\n",
        "\n",
        "model = LogisticRegression(max_iter =400, solver='lbfgs', C= 1 )\n",
        "\n",
        "poly = PolynomialFeatures(degree = 2,interaction_only=False, include_bias=False)\n",
        "\n",
        "X_train_poly= poly.fit_transform(X_train)\n",
        "\n",
        "model.fit( X_train_poly, y_train.label)\n",
        "\n",
        "model.coef_, model.intercept_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test poly\n",
        "x_t = X_train_poly[0:5]\n",
        "y_t = y_test.head()\n",
        "#print(X_test.head(), y_test.head())\n",
        "pred1= model.predict( x_t)\n",
        "#proba1= model.predict_proba( np.array(x_t, ndmin=2) )\n",
        "proba1= model.predict_proba(x_t)\n",
        "print(\"For parameters = {}{}, we predict {} proba={}\".format(x_t, y_t, pred1, proba1[:,1]))\n",
        "\n",
        "model_accuracy=model.score(X_train_poly,  y_test.label)\n",
        "y_pred= model.predict( X_train_poly)\n",
        "calc_accuracy =  sum(y_pred == y_test.label) /  y_test.label.count()\n",
        "print(\"Test  Count={}; Model Accuracy= {} ; Calculated Accuracy={}\".format( y_test.label.count(), model_accuracy, calc_accuracy) )"
      ],
      "metadata": {
        "id": "lzOhA_KjFjzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "a= X[y.label == True]\n",
        "b=y\n",
        "#a1 =  math.radians( a['Ang1'] )\n",
        "x1 =  np.cos( np.radians( a['Ang1'] ) ) + np.cos( np.radians( a['Ang2'] ) )\n",
        "y1 =  np.sin( np.radians( a['Ang1'] ) ) + np.sin( np.radians( a['Ang2'] ) )\n",
        "\n",
        "print(a,x1, y1 )"
      ],
      "metadata": {
        "id": "SXKdaIztMZuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqxLJd46p_EH"
      },
      "source": [
        "# Create chart\n",
        "#fig, ax= pltp.plot(figsize=(20,10)).subplots()\n",
        "fig, ax= pltp.subplots()\n",
        "\n",
        "\n",
        "ser1p = ax.scatter(x1,y1, color='green', marker='o', linewidth='1', label='True', xticks=0.05)\n",
        "#ser2p = ax.scatter(neg.circuit1,neg.circuit2, color=\"red\", marker='o', edgecolor='black', linewidth='1', label='False')\n",
        "\n",
        "\n",
        "#CS =ax.contour(xx, yy, probs, levels=[.5], colors='green')\n",
        "#CS.collections[0].set_label('Decision Boundary 0.5')\n",
        "\n",
        "#CS =ax.contour(xx, yy, probs, levels=[.95], colors='blue')\n",
        "#CS.collections[0].set_label('Decision Boundary 0.95')\n",
        "\n",
        "#CS =ax.contour(xx, yy, probs, levels=[.05], colors='blue')\n",
        "#CS.collections[0].set_label('Decision Boundary 0.05')\n",
        "\n",
        "\n",
        "pltp.xlabel(\"circuit1\")\n",
        "pltp.ylabel(\"circuit2\")\n",
        "\n",
        "pltp.legend(loc='upper right')\n",
        "\n",
        "pltp.axis([-3, 3, -3, 3])\n",
        "\n",
        "\n",
        "pltp.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YC84JFJIGIp"
      },
      "source": [
        "# Create chart\n",
        "#fig, ax= pltp.plot(figsize=(20,10)).subplots()\n",
        "fig, ax= pltp.subplots()\n",
        "\n",
        "\n",
        "ser1p = ax.scatter(X_test.,pos.circuit2, color='green', marker='o', linewidth='1', label='True')\n",
        "ser2p = ax.scatter(neg.circuit1,neg.circuit2, color=\"red\", marker='o', edgecolor='black', linewidth='1', label='False')\n",
        "\n",
        "\n",
        "#CS =ax.contour(xx, yy, probs, levels=[.5], colors='green')\n",
        "#CS.collections[0].set_label('Decision Boundary 0.5')\n",
        "\n",
        "CS =ax.contour(xx, yy, probs, levels=[.95], colors='blue')\n",
        "CS.collections[0].set_label('Decision Boundary 0.95')\n",
        "\n",
        "#CS =ax.contour(xx, yy, probs, levels=[.05], colors='blue')\n",
        "#CS.collections[0].set_label('Decision Boundary 0.05')\n",
        "\n",
        "\n",
        "pltp.xlabel(\"circuit1\")\n",
        "pltp.ylabel(\"circuit2\")\n",
        "\n",
        "pltp.legend(loc='upper right')\n",
        "\n",
        "pltp.axis([-10, 15, -10, 15])\n",
        "\n",
        "\n",
        "pltp.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-EtI6xOE642"
      },
      "source": [
        "Polynomial Boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeHIExUnUlGJ"
      },
      "source": [
        "x1val= [[8,0,1.61,-205],[8.0, 0, 1.61, -35],[2.0, 0, 2.00, -165] ,[4.5, 0, 0.89, -245]]\n",
        "\n",
        "#x1val = [[0,.5],[-.5,-.5]]\n",
        "x1=  poly.fit_transform(x1val)\n",
        "\n",
        "pred1= model.predict( x1)\n",
        "proba1= model.predict_proba( x1)\n",
        "print(\"For parameters = {}, we predict {} proba={}\".format(x1val, pred1, proba1[:,1]))\n",
        "\n",
        "\n",
        "model_accuracy=model.score(X_train_poly,  y.label)\n",
        "\n",
        "\n",
        "y_pred= model.predict( X_train_poly)\n",
        "\n",
        "calc_accuracy =  sum(y_pred == y.label) /  y.label.count()\n",
        "\n",
        "print(\"\\nModel Accuracy {} ; Calculated Accuracy={}\\n\\n\".format(model_accuracy, calc_accuracy) )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVeV7E61OSJ8"
      },
      "source": [
        "# Chart\n",
        "ser1 = plt.scatter(df..circuit1,pos.circuit2, color='green', marker='o', linewidth='1', label='True')\n",
        "ser2 = plt.scatter(neg.circuit1,neg.circuit2, color=\"red\", marker='o', edgecolor='black', linewidth='1', label='False')\n",
        "\n",
        "plt.xlabel('Circuit 1')\n",
        "plt.ylabel('Circuit 2')\n",
        "\n",
        "a = model.intercept_[0]\n",
        "b = model.coef_[0][0]\n",
        "c= model.coef_[0][1]\n",
        "#c = model.coef_[1]\n",
        "\n",
        "# plot decision boundary\n",
        "\n",
        "# getting the x co-ordinates of the decision boundary\n",
        "plot_x = np.array([min(X_train.circuit1) - 0.2, max(X_train.circuit1) + 0.2])\n",
        "# getting corresponding y co-ordinates of the decision boundary\n",
        "plot_y = (-1/c) * (b * plot_x + a)\n",
        "\n",
        "\n",
        "# Plotting the Single Line Decision Boundary\n",
        "plt.plot(plot_x, plot_y, label = \"Decision_Boundary\")\n",
        "\n",
        "\n",
        "plt.title('Data set')\n",
        "\n",
        "plt.axis([-10, 15, -10, 15])\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}